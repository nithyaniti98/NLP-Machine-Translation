{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vm6ezIQ3ncN7"
   },
   "source": [
    "# Import and preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will load packages and models required for this NLP task and the dataset of English and German sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "FZFeOqwTtRqB",
    "outputId": "495219cc-2433-4c07-8576-64c4e7900c23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-27 15:40:10--  https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n",
      "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
      "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/104ea/en-de.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c16166187db0c0fa5523e643103efd4841ce73060c24e346d49d11b175ba764e&X-Amz-Date=20200227T154011Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200227%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
      "--2020-02-27 15:40:11--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/104ea/en-de.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=c16166187db0c0fa5523e643103efd4841ce73060c24e346d49d11b175ba764e&X-Amz-Date=20200227T154011Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200227%2Fnewcodalab%2Fs3%2Faws4_request\n",
      "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
      "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 864010 (844K) [application/zip]\n",
      "Saving to: ‘ende_data.zip’\n",
      "\n",
      "ende_data.zip       100%[===================>] 843.76K  1.51MB/s    in 0.5s    \n",
      "\n",
      "2020-02-27 15:40:12 (1.51 MB/s) - ‘ende_data.zip’ saved [864010/864010]\n",
      "\n",
      "Archive:  ende_data.zip\n",
      "  inflating: dev.ende.mt             \n",
      "  inflating: dev.ende.scores         \n",
      "  inflating: dev.ende.src            \n",
      "  inflating: test.ende.mt            \n",
      "  inflating: test.ende.src           \n",
      "  inflating: train.ende.mt           \n",
      "  inflating: train.ende.scores       \n",
      "  inflating: train.ende.src          \n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "if not exists('ende_data.zip'):\n",
    "    !wget -O ende_data.zip https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n",
    "    !unzip ende_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "OkcVELakhdvl",
    "outputId": "05ce4723-b624-4adb-89d8-64924fcaefe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "h6-pbpD7tWJa",
    "outputId": "f2c6dfee-2fe1-4a95-ff9e-36f490047d22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import talos\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from string import digits\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rpBwPCXPhLlZ",
    "outputId": "0daf6edb-1153-486b-f630-ad45466d5f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words_en = set(stopwords.words('english'))\n",
    "stop_words_de = set(stopwords.words('german'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading the sentences from the dataset, we perform basic preprocessing which include lowercasing the words, splitting connected words and remove punctuation or symbols in the remove_list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1W1ijlFtb8P"
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "remove_list = ['\\n', '.', ',', '/', '\\'', '-', '_']\n",
    "\n",
    "# Method to preprocess individual english sentences.\n",
    "# Parameters: a single string representing a sentence. \n",
    "# Returns: a single string after pre-processing\n",
    "def preprocess_eng(line):\n",
    "    text = line.lower()\n",
    "    l = line.split(\" \")\n",
    "    \n",
    "    for i, word in enumerate(l):\n",
    "        if '_' in word:\n",
    "            changed = True\n",
    "            del l[i]\n",
    "            l[i:i] = re.sub('_', ' ', word).split()\n",
    "        elif '/' in word:\n",
    "            changed = True\n",
    "            del l[i]\n",
    "            l[i:i] = re.sub('/', ' / ', word).split()\n",
    "        elif len(' '.join(word.split('-')).split())>=2:\n",
    "            changed = True\n",
    "            del l[i]\n",
    "            l[i:i] = re.sub('-', ' ', word).split()\n",
    "    \n",
    "    l = ' '.join([word for word in l if (word not in remove_list and word not in stop_words_en)])\n",
    "    return l\n",
    "\n",
    "# Wrapping method that extracts and preprocess english sentences in a file.\n",
    "# Parameters: file. Returns: list of sentences.\n",
    "def get_sentences_eng(f):\n",
    "    file = open(f)\n",
    "    lines = file.readlines()\n",
    "    sentences = []\n",
    "    \n",
    "    for l in lines:\n",
    "        l = l.translate(str.maketrans('', '', string.punctuation))\n",
    "        l = l.rstrip('\\n').lower()\n",
    "        l = l.translate(str.maketrans('', '', digits))\n",
    "        sentences.append(preprocess_eng(l))\n",
    "        #sentences.append(l)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SM5uFShT7SgT"
   },
   "outputs": [],
   "source": [
    "# Method to preprocess individual german sentences.\n",
    "# Parameters: a single string representing a sentence. \n",
    "# Returns: a single string after pre-processing\n",
    "def preprocess_de(line):\n",
    "    text = line.lower()\n",
    "    l = line.split(\" \")\n",
    "    \n",
    "    for i, word in enumerate(l):\n",
    "        if '_' in word:\n",
    "            changed = True\n",
    "            del l[i]\n",
    "            l[i:i] = re.sub('_', ' ', word).split()\n",
    "        elif '/' in word:\n",
    "            changed = True\n",
    "            del l[i]\n",
    "            l[i:i] = re.sub('/', ' / ', word).split()\n",
    "        elif len(' '.join(word.split('-')).split())>=2:\n",
    "            changed = True\n",
    "            del l[i]\n",
    "            l[i:i] = re.sub('-', ' ', word).split()\n",
    "    \n",
    "    l = ' '.join([word for word in l if (word not in remove_list and word not in stop_words_de)])\n",
    "    return l\n",
    "\n",
    "# Wrapping method that extracts and preprocess german sentences in a file.\n",
    "# Parameters: file. Returns: list of sentences.\n",
    "def get_sentences_de(f):\n",
    "    file = open(f)\n",
    "    lines = file.readlines()\n",
    "    sentences = []\n",
    "    \n",
    "    for l in lines:\n",
    "        l = l.translate(str.maketrans('', '', string.punctuation))\n",
    "        l = l.rstrip('\\n').lower()\n",
    "        l = l.translate(str.maketrans('', '', digits))\n",
    "        sentences.append(preprocess_de(l))\n",
    "        #sentences.append(l)\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyAL9rA6txpq"
   },
   "outputs": [],
   "source": [
    "german_train = get_sentences_de('train.ende.mt') + get_sentences_de('dev.ende.mt')\n",
    "english_train = get_sentences_eng('train.ende.src') + get_sentences_eng('dev.ende.src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "colab_type": "code",
    "id": "j5je8iBnwQil",
    "outputId": "5708f44d-b48c-4f99-f7ca-2b62510e1340"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f22a8f26710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x7f22a8c6e5c0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in english_train[:]:\n",
    "      eng_l.append(len(i.split()))\n",
    "\n",
    "for i in german_train[:]:\n",
    "      deu_l.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})\n",
    "\n",
    "length_df.hist(bins = 20) # Histogram of length of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4nvkr7zUxIS6",
    "outputId": "da35b676-1428-46cb-a379-9490f781a667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 167,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get maximum sentence length for embedding\n",
    "print(np.amax(length_df.eng.values))\n",
    "np.amax(length_df.deu.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zaGoQiOanvir"
   },
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains the word embedding Keras Tokenizer model used. All sentences are then padded to ensure they are of equal length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iaqdcujywo5f"
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "      tokenizer = Tokenizer()\n",
    "      tokenizer.fit_on_texts(lines)\n",
    "      return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "A99f1M9bw7hO",
    "outputId": "8de156d5-9e94-423f-9013-3dbd82435158"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Vocabulary Size: 26708\n"
     ]
    }
   ],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(english_train[:])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 22\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AMokcTaCxdOn",
    "outputId": "43873122-5e2c-40d3-e674-2d3fc34f776f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deutch Vocabulary Size: 29475\n"
     ]
    }
   ],
   "source": [
    "# prepare German tokenizer\n",
    "deu_tokenizer = tokenization(german_train[:])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 22\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7StfwSGKxlDX"
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "         # integer encode sequences\n",
    "         seq = tokenizer.texts_to_sequences(lines)\n",
    "         # pad sequences with 0 values\n",
    "         seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "         return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xcs6LubVn6wg"
   },
   "source": [
    "# Prepare training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4RDTPZUT2SbP"
   },
   "outputs": [],
   "source": [
    "with open(\"./train.ende.scores\", \"r\") as f:\n",
    "  train_scores = [l.rstrip('\\n') for l in f.readlines()]\n",
    "with open(\"./dev.ende.scores\", \"r\") as f:\n",
    "  val_scores = [l.rstrip('\\n') for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "011qkSpp2XuI"
   },
   "outputs": [],
   "source": [
    "train_scores = np.array(train_scores + val_scores).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xMvYxUTW5sPF"
   },
   "outputs": [],
   "source": [
    "min_score = np.amin(train_scores)\n",
    "max_score = np.amax(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOcXgIlYNYuO"
   },
   "outputs": [],
   "source": [
    "# Labels are scaled for the model\n",
    "train_scores -= min_score\n",
    "train_scores /= np.ptp(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lQ6rdYRx3yYY"
   },
   "outputs": [],
   "source": [
    "german_train = encode_sequences(deu_tokenizer, deu_length, german_train)\n",
    "english_train = encode_sequences(eng_tokenizer, eng_length, english_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6ZqX0C7tvdB"
   },
   "outputs": [],
   "source": [
    "german_test = get_sentences_de('test.ende.mt')\n",
    "german_test = encode_sequences(deu_tokenizer, deu_length, german_test)\n",
    "english_test = get_sentences_eng('test.ende.src')\n",
    "english_test = encode_sequences(eng_tokenizer, eng_length, english_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YFy2eTgY4U7_"
   },
   "outputs": [],
   "source": [
    "# This cell shuffles and splits the data to get an effective split\n",
    "split = int(0.8*len(german_train))\n",
    "p = np.random.permutation(len(german_train))\n",
    "german_training = german_train[p][:split]\n",
    "german_val = german_train[p][split:]\n",
    "\n",
    "english_training = english_train[p][:split]\n",
    "english_val = english_train[p][split:]\n",
    "\n",
    "scores_training = np.array(train_scores)[p][:split]\n",
    "scores_val = np.array(train_scores)[p][split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GidrhqDl6dbc"
   },
   "outputs": [],
   "source": [
    "train = np.stack((german_training,english_training),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsR-Sz1w_fp1"
   },
   "outputs": [],
   "source": [
    "val = np.stack((german_val,english_val),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rxhwg5yTt821"
   },
   "outputs": [],
   "source": [
    "test = np.stack((german_test,english_test),axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hGdSjV08TIY"
   },
   "outputs": [],
   "source": [
    "vocabulary = len(deu_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BKKDdDZ-oCI-"
   },
   "source": [
    "# Training MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains the Keras regression model used for predicting the translation score. The model has their parameters optimised by the package talos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, TimeDistributed, Flatten, Dropout, Activation, Reshape\n",
    "from keras import optimizers\n",
    "from keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that builds and trains model\n",
    "def mlp_model(x_train, y_train, x_val, y_val=None, params):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(22,2)))\n",
    "    model.add(Embedding(vocabulary,params['hidden_size'] ,input_length=44))\n",
    "    model.add(LSTM(params['hidden_size']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(params['hidden_size']))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('relu'))\n",
    "    model.compile(loss='mse', optimizer=params['optimizer'](lr=params['lr']), metrics=['mse'])\n",
    "    \n",
    "    if y_val is not None: # Return to talos function\n",
    "      history = model.fit(x_train, y_train, batch_size=params['batch_size'], \n",
    "                          epochs=params['epochs'], validation_data=(x_val, y_val))\n",
    "      return history, model\n",
    "    else: # Return to predict output\n",
    "      model.fit(x_train, y_train)\n",
    "      return model.predict(x_val), model\n",
    "\n",
    "mlp_params = {\n",
    "    'hidden_size':(300, 512, 5),\n",
    "    'dropout':(0.2, 0.5, 3),\n",
    "    'lr':[0.00001, 0.0001, 0.001],\n",
    "    'optimizer':['RMSprop', 'Adam', 'Nadam'],\n",
    "    'batch_size':[32,64,96,128]\n",
    "    'epochs':[1,5,10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = talos.Scan(x=train, y=scores_training, model=mlp_model, fraction_limit=0.05,\n",
    "               params=mlp_params, experiment_name='MLP')\n",
    "r = talos.Reporting(t)\n",
    "mlp_best_params = r.best_params\n",
    "# r.data.sort_values(by=['val_mean_squared_error']) #run if you want to receive table of tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2huFF7PKOVmo",
    "outputId": "1683971b-b735-4bba-96b9-890b3da9f259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 44)                0         \n",
      "_________________________________________________________________\n",
      "embedding_8 (Embedding)      (None, 44, 512)           10240000  \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 513       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 14,440,961\n",
      "Trainable params: 14,440,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(22,2)))\n",
    "model.add(Embedding(vocabulary,hidden_size ,input_length=44))\n",
    "model.add(LSTM(hidden_size))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('relu'))\n",
    "rms = optimizers.RMSprop(lr=0.00001)\n",
    "model.compile(loss='mse', optimizer=rms, metrics=['mse'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "fL-DQ8_OOUwz",
    "outputId": "a4ebfe5b-5233-4a25-87e8-7024492328bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 1600 samples\n",
      "Epoch 1/1\n",
      "6400/6400 [==============================] - 13s 2ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f22a8548cf8>"
      ]
     },
     "execution_count": 193,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, mlp_model = mlp_model(train, scores_training, val, None, mlp_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_LBSRaRIoF0s"
   },
   "source": [
    "# Evaluating Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__B2y3of_tiw"
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "predictions = np.squeeze(predictions)\n",
    "pearson = pearsonr(scores_val, predictions)\n",
    "pearson[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XG7aTPVGoQVE"
   },
   "source": [
    "# Output Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WqLiUUfBAnsi"
   },
   "outputs": [],
   "source": [
    "test_predictions = np.squeeze(mlp_model.predict(test))\n",
    "test_predictions*=max_score-min_score\n",
    "test_predictions+=min_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzeZ_fDoyfHp"
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "def writeScores(scores):\n",
    "    fn = \"predictions.txt\"\n",
    "    print(\"\")\n",
    "    with open(fn, 'w') as output_file:\n",
    "        for idx,x in enumerate(scores):\n",
    "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
    "            #print(out)\n",
    "            output_file.write(f\"{x}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "j2k2nivsyhoW",
    "outputId": "768d5da9-88ee-406c-fd31-c8267c551e79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "writeScores(pred)\n",
    "\n",
    "with ZipFile(\"en-de_svr.zip\",\"w\") as newzip:\n",
    "\tnewzip.write(\"predictions.txt\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "NLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
